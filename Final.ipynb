{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import colorsys\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "        \n",
    "def face_detection(file):\n",
    "    \n",
    "    ## face detector와 landmark predictor 정의\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    # 파일에서 이미지 불러오기\n",
    "    file_name=file\n",
    "    \n",
    "    # 파일 이름과 확장자 분리\n",
    "    name=file_name.split(\".\")[0]\n",
    "    ext=file_name.split(\".\")[1]\n",
    "\n",
    "    img=dlib.load_rgb_image(file_name)\n",
    "\n",
    "    cvImg=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    #이미지를 두배로 키움\n",
    "    cvImg = cv2.resize(cvImg, None, fx=2, fy=2, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 얼굴 인식 두번째 변수 1은 업샘플링을 한번 하겠다는 얘기\n",
    "    # 업샘플링을하면 더 많이 인식할 수 있음\n",
    "    # 값이 커질수록 느리고 메모리도 많이 잡아먹음\n",
    "    dets = detector(img, 1)\n",
    "    \n",
    "    # 입술 좌표를 담는 리스트\n",
    "    lip_x=[]\n",
    "    lip_y=[]\n",
    "\n",
    "    # 인식된 얼굴 개수 출력 \n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "\n",
    "    # 인식된 얼굴 개수만큼 반복하여 얼굴 윤곽 표시\n",
    "    for k, d in enumerate(dets):\n",
    "        # k 얼굴 인덱스\n",
    "        # d 얼굴 좌표\n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "            k, d.left(), d.top(), d.right(), d.bottom()))\n",
    "\n",
    "        # 인식된 좌표에서 랜드마크 추출 \n",
    "        shape = predictor(img, d)\n",
    "        print(shape.num_parts)\n",
    "        \n",
    "        # num_parts(랜드마크 구조체)를 하나씩 접근\n",
    "        for i in range(0, shape.num_parts):\n",
    "            \n",
    "            # 해당 x,y 좌표를 두배로 키워 좌표를 얻음\n",
    "            x = shape.part(i).x*2\n",
    "            y = shape.part(i).y*2\n",
    "            \n",
    "            # 입술 랜드마크범위에 해당하는 좌표 \n",
    "            if(48<=i & i<=60):\n",
    "                lip_x.append(x)\n",
    "                lip_y.append(y)\n",
    "\n",
    "            # 이미지 랜드마크 좌표 지점에 인덱스(랜드마크번호, 여기선 i)를 putText로 표시\n",
    "            # cv2.putText(cvImg, str(i), (x, y), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 0.3, (0, 255, 0))                    \n",
    "\n",
    "    # 입술 crop\n",
    "    src=cvImg\n",
    "    dst=src.copy()\n",
    "    dst=src[min(lip_y):max(lip_y),min(lip_x):max(lip_x)]\n",
    "    \n",
    "    # 입술 저장\n",
    "    lip_file=name+\"_lip.\"+ext\n",
    "    cv2.imwrite(name+\"_lip.\"+ext, dst)\n",
    "    \n",
    "    # 입술 저장된 파일 이름 return\n",
    "    return lip_file\n",
    "\n",
    "def tracking(img_name): # img_name = 추출할 이미지 경로 혹은 이름\n",
    "    \n",
    "    img = cv2.imread(img_name) \n",
    "    \n",
    "    # 입술색 추출 범위\n",
    "    lower_red = np.array([100, 0, 0]) \n",
    "    upper_red = np.array([255, 120, 200])\n",
    "\n",
    "    hsv = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    red_range = cv2.inRange(hsv,lower_red,upper_red)\n",
    "\n",
    "    red_result = cv2.bitwise_and(img,img,mask = red_range)\n",
    "    red_result = cv2.resize(red_result,(300,300))\n",
    "\n",
    "    img = cv2.resize(img,(300,300))\n",
    "\n",
    "\n",
    "    #추출한 이미지 저장\n",
    "    cv2.imwrite('result1.PNG', red_result)\n",
    "    \n",
    "    return\n",
    "\n",
    "def centroid_histogram(clt):\n",
    "    \n",
    "    # grab the number of different clusters and create a histogram\n",
    "    # based on the number of pixels assigned to each cluster\n",
    "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(clt.labels_, bins=numLabels)\n",
    "\n",
    "    # normalize the histogram, such that it sums to one\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "\n",
    "    # return the histogram\n",
    "    return hist\n",
    "\n",
    "# 색분율 시각화\n",
    "def plot_colors(hist, centroids):\n",
    "    \n",
    "    # initialize the bar chart representing the relative frequency\n",
    "    # of each of the colors\n",
    "    bar = np.zeros((50, 300, 3), dtype=\"uint8\")\n",
    "    startX = 0\n",
    "\n",
    "    # loop over the percentage of each cluster and the color of\n",
    "    # each cluster\n",
    "    for (percent, color) in zip(hist, centroids):\n",
    "        # plot the relative percentage of each cluster\n",
    "        endX = startX + (percent * 300)\n",
    "        cv2.rectangle(bar, (int(startX), 0), (int(endX), 50),\n",
    "                      color.astype(\"uint8\").tolist(), -1)\n",
    "        startX = endX\n",
    "\n",
    "    # return the bar chart\n",
    "    return bar\n",
    "\n",
    "def image_color_cluster():\n",
    "    image = cv2.imread(\"result1.PNG\")\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3)) # height, width 통합\n",
    "    \n",
    "    # K-Means Clustering\n",
    "    k = 5 \n",
    "    clt = KMeans(n_clusters = k,random_state=5) \n",
    "    clt.fit(image)\n",
    "    \n",
    "    # 색 분율\n",
    "    hist = centroid_histogram(clt)\n",
    "    \n",
    "    print(\"=====분율====\")\n",
    "    print(hist)\n",
    "    print(\"=====rgb=====\")\n",
    "    for center in clt.cluster_centers_:\n",
    "        print(center)\n",
    "    print(\"=====max red=====\")\n",
    "    max_val = 0 \n",
    "    max_red = []\n",
    "    \n",
    "    # 검은색을 제외한 색 분율이 가장 높은 색의 r,g,b 값을 가져옴\n",
    "    i = 0\n",
    "    for center in clt.cluster_centers_ :\n",
    "        if center[0]>1 and center[1]>1 and center[2]>1 and max_val < hist[i] :\n",
    "            max_val = hist[i]\n",
    "            max_red=center.copy()\n",
    "        i=i+1\n",
    "        \n",
    "    print(max_red)\n",
    "\n",
    "    bar = plot_colors(hist, clt.cluster_centers_)\n",
    "\n",
    "    # show our color bart\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(bar)\n",
    "    plt.show()\n",
    "\n",
    "    return max_red\n",
    "\n",
    "# 최종 테스트\n",
    "def result(max_red):\n",
    "    \n",
    "    # 모델 불러오기\n",
    "    rf_clf = joblib.load('RF_model.pkl') \n",
    "    \n",
    "    bg_clf = joblib.load('BG_model.pkl') \n",
    "\n",
    "    # input 이미지의 r,g,b 추출값\n",
    "    r,g,b=max_red\n",
    "    h,s,v=colorsys.rgb_to_hsv(r,g,b)\n",
    "    inputs=[[r,g,b,h,s]]\n",
    "    inputlist=np.array(inputs)\n",
    "    inputlist.reshape(-1,1)\n",
    "\n",
    "    # 예측\n",
    "    rf_pred=rf_clf.predict(inputlist)\n",
    "    bg_pred=bg_clf.predict(inputlist)\n",
    "\n",
    "    # 예측한 립스틱 name 찾기\n",
    "    test=pd.read_csv(\"data_with_mode_s.csv\")\n",
    "    \n",
    "    mode_list=test.drop_duplicates(['name'],keep='first')\n",
    "    \n",
    "    rf=mode_list[mode_list[\"mode\"]==rf_pred[0]]\n",
    "    bg=mode_list[mode_list[\"mode\"]==bg_pred[0]]\n",
    "    \n",
    "    print(\"Random Forest Model이 예측한 립스틱: \", list(rf[\"name\"]))\n",
    "    print(\"Bagging Model이 예측한 립스틱: \", list(bg[\"name\"]))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n",
      "Detection 0: Left: 167 Top: 133 Right: 322 Bottom: 288\n",
      "68\n",
      "=====분율====\n",
      "[0.58034444 0.09196667 0.0701     0.15744444 0.10014444]\n",
      "=====rgb=====\n",
      "[1.48632248 0.65420471 0.70418653]\n",
      "[217.98972934  37.62916868  59.2257129 ]\n",
      "[115.98685877  47.83438885  51.73084231]\n",
      "[200.22336745   6.98623367  10.56837275]\n",
      "[223.69757885  83.70068858 108.83296313]\n",
      "=====max red=====\n",
      "[200.22336745   6.98623367  10.56837275]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAABTElEQVR4nO3aoXEDMRBAUctj5AZMTVKFawh0A27JLDWkn3MpYQoLi9n9A/ce3Rlp0R8BjTnnAYDGcesFAPZEdAFCogsQEl2AkOgChEQXIHR6NzyO4T8Zu/f6uG1y79f5Z9Xz78uy6vm1y+dj6xX+XL+f47+Zly5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugChMefcegeA3fDSBQiJLkBIdAFCogsQEl2AkOgChH4Bd7gOh/Lz4JkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model이 예측한 립스틱:  ['GorgioArmani_lipmagnet400', 'CHANEL_TRUERED', 'YSL_ROUGE', 'est_imotal']\n",
      "Bagging Model이 예측한 립스틱:  ['GorgioArmani_lipmagnet400', 'CHANEL_TRUERED', 'YSL_ROUGE', 'est_imotal']\n"
     ]
    }
   ],
   "source": [
    "# 이미지 경로\n",
    "file_name=\"수지.jpg\"\n",
    "# 추출한 입술 이미지 경로\n",
    "lip_file=face_detection(file_name)\n",
    "# 색 범위 masking\n",
    "tracking(lip_file)\n",
    "# 색 추출\n",
    "max_red=image_color_cluster()\n",
    "# 최종 예측\n",
    "result(max_red)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
